{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1eee98",
   "metadata": {},
   "source": [
    "# Laufzeitanalyse: SHAP vs SHAPIQ\n",
    "\n",
    "Dieses Notebook vergleicht verschiedene Approximationsverfahren zur Berechnung von Shapley-Werten.\n",
    "\n",
    "### Ziel\n",
    "Analyse von:\n",
    "- Laufzeit (x-Achse)\n",
    "- Approximationsgenauigkeit (L1 & L2 Fehler) gegen√ºber Referenzwerten\n",
    "\n",
    "##### Verglichene Methoden\n",
    "| Bibliothek | Methode                  |\n",
    "|------------|--------------------------|\n",
    "| `shapiq`   | KernelSHAP, SVARM, PermutationSamplingSV |\n",
    "| `shap`     | KernelExplainer, PermutationExplainer    |\n",
    "\n",
    "##### Datens√§tze\n",
    "- Bike Sharing\n",
    "- California Housing\n",
    "\n",
    "##### Modelle\n",
    "- Lineare Regression\n",
    "- Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f93473",
   "metadata": {},
   "source": [
    "Imports & Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1152e847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:43.453842Z",
     "start_time": "2025-07-20T20:59:42.282747Z"
    }
   },
   "outputs": [],
   "source": [
    "import shapiq\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import shap\n",
    "from shapiq import TabularExplainer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033f3f8",
   "metadata": {},
   "source": [
    "Daten vorbereiten & subsample Background (f√ºr schnellere Laufzeiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7188ab98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:43.525014Z",
     "start_time": "2025-07-20T20:59:43.456837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike Sharing - X shape: (17379, 12) y shape: (17379,)\n",
      "California Housing - X shape: (20640, 8) y shape: (20640,)\n",
      "Sampled preprocessed Bike Sharing shape: (1738, 16)\n",
      "Sampled preprocessed California Housing shape: (2064, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- Daten laden und vorverarbeiten ---\n",
    "\n",
    "X_bike, y_bike = shapiq.datasets.load_bike_sharing()\n",
    "X_cal, y_cal = shapiq.datasets.load_california_housing()\n",
    "\n",
    "print(\"Bike Sharing - X shape:\", X_bike.shape, \"y shape:\", y_bike.shape)\n",
    "print(\"California Housing - X shape:\", X_cal.shape, \"y shape:\", y_cal.shape)\n",
    "\n",
    "def preprocess_data(X, y, categorical_cols=None, sample_size=None):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        if categorical_cols is not None:\n",
    "            X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "        else:\n",
    "            cat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "            X_processed = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    else:\n",
    "        X_processed = pd.DataFrame(X)\n",
    "    \n",
    "    y_processed = pd.Series(y) if not isinstance(y, pd.Series) else y\n",
    "    \n",
    "    if sample_size is not None and len(X_processed) > sample_size:\n",
    "        sampled_indices = X_processed.sample(n=sample_size, random_state=42).index\n",
    "        X_processed = X_processed.loc[sampled_indices].reset_index(drop=True)\n",
    "        y_processed = y_processed.loc[sampled_indices].reset_index(drop=True)\n",
    "    else:\n",
    "        X_processed = X_processed.reset_index(drop=True)\n",
    "        y_processed = y_processed.reset_index(drop=True)\n",
    "    \n",
    "    return X_processed, y_processed\n",
    "\n",
    "bike_categorical_cols = ['season', 'weather']\n",
    "\n",
    "X_bike_proc, y_bike_proc = preprocess_data(X_bike, y_bike, categorical_cols=bike_categorical_cols)\n",
    "X_cal_proc, y_cal_proc = preprocess_data(X_cal, y_cal)\n",
    "\n",
    "sample_fraction = 0.1\n",
    "\n",
    "X_bike_proc_sampled = X_bike_proc.sample(frac=sample_fraction, random_state=42)\n",
    "y_bike_proc_sampled = y_bike_proc.loc[X_bike_proc_sampled.index]\n",
    "\n",
    "X_cal_proc_sampled = X_cal_proc.sample(frac=sample_fraction, random_state=42)\n",
    "y_cal_proc_sampled = y_cal_proc.loc[X_cal_proc_sampled.index]\n",
    "\n",
    "print(\"Sampled preprocessed Bike Sharing shape:\", X_bike_proc_sampled.shape)\n",
    "print(\"Sampled preprocessed California Housing shape:\", X_cal_proc_sampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df289d",
   "metadata": {},
   "source": [
    "Modelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42226904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.144514Z",
     "start_time": "2025-07-20T20:59:43.673427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike Sharing RandomForestRegressor trainiert.\n",
      "California Housing RandomForestRegressor trainiert.\n",
      "Bike Sharing LinearRegression trainiert.\n",
      "California Housing LinearRegression trainiert.\n",
      "Number of features in bike dataset: 16\n",
      "Number of features in cal dataset: 8\n"
     ]
    }
   ],
   "source": [
    "# --- Train-Test Split ---\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
    "    X_bike_proc_sampled, y_bike_proc_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_cal_proc_sampled, y_cal_proc_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Modelle trainieren ---\n",
    "\n",
    "model_bike_rf = RandomForestRegressor(random_state=42)\n",
    "model_bike_rf.fit(Xb_train, yb_train)\n",
    "print(\"Bike Sharing RandomForestRegressor trainiert.\")\n",
    "\n",
    "model_cal_rf = RandomForestRegressor(random_state=42)\n",
    "model_cal_rf.fit(Xc_train, yc_train)\n",
    "print(\"California Housing RandomForestRegressor trainiert.\")\n",
    "\n",
    "model_bike_lr = LinearRegression()\n",
    "model_bike_lr.fit(Xb_train, yb_train)\n",
    "print(\"Bike Sharing LinearRegression trainiert.\")\n",
    "\n",
    "model_cal_lr = LinearRegression()\n",
    "model_cal_lr.fit(Xc_train, yc_train)\n",
    "print(\"California Housing LinearRegression trainiert.\")\n",
    "\n",
    "# --- Wrapper Funktion f√ºr sauberes predict mit Feature-Namen ---\n",
    "\n",
    "def model_predict_wrapper(model, feature_names):\n",
    "    def predict(X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X, columns=feature_names)\n",
    "        elif isinstance(X, pd.Series):\n",
    "            # convert Series to DataFrame with one row\n",
    "            X = pd.DataFrame([X.values], columns=feature_names)\n",
    "        elif not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be DataFrame, Series, or 2D NumPy array.\")\n",
    "        return model.predict(X)\n",
    "    return predict\n",
    "\n",
    "\n",
    "# Feature-Namen\n",
    "feature_names_bike = X_bike_proc_sampled.columns.tolist()\n",
    "feature_names_cal = X_cal_proc_sampled.columns.tolist()\n",
    "\n",
    "n_features_bike = X_bike_proc_sampled.shape[1]\n",
    "n_features_cal = X_cal_proc_sampled.shape[1]\n",
    "\n",
    "print(f\"Number of features in bike dataset: {n_features_bike}\")\n",
    "print(f\"Number of features in cal dataset: {n_features_cal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10743980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.174285Z",
     "start_time": "2025-07-20T20:59:45.171113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgnosticExplainer', 'Explainer', 'TabPFNExplainer', 'TabularExplainer', 'TreeExplainer', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'agnostic', 'base', 'configuration', 'custom_types', 'tabpfn', 'tabular', 'tree', 'utils', 'validation']\n"
     ]
    }
   ],
   "source": [
    "import shapiq.explainer\n",
    "\n",
    "print(dir(shapiq.explainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382a3a60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.227326Z",
     "start_time": "2025-07-20T20:59:45.224154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'Explainer', 'ExplainerIndices', 'InteractionValues', 'Literal', 'TYPE_CHECKING', 'TabularExplainer', 'TabularExplainerApproximators', 'TabularExplainerImputers', 'TabularExplainerIndices', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'annotations', 'finalize_computed_interactions', 'overrides', 'setup_approximator', 'warn']\n"
     ]
    }
   ],
   "source": [
    "import shapiq.explainer.tabular\n",
    "\n",
    "print(dir(shapiq.explainer.tabular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d3bda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.235485Z",
     "start_time": "2025-07-20T20:59:45.232425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typing.Literal['spex', 'montecarlo', 'svarm', 'permutation', 'regression']\n"
     ]
    }
   ],
   "source": [
    "from shapiq.explainer.tabular import TabularExplainerApproximators\n",
    "\n",
    "print(TabularExplainerApproximators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c90bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:54.846953Z",
     "start_time": "2025-07-20T20:59:45.259274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike background shape: (100, 16)\n",
      "Bike feature names len: 16\n",
      "Cal background shape: (100, 8)\n",
      "Cal feature names len: 8\n",
      "type(background_bike_np): <class 'numpy.ndarray'>\n",
      "background_bike_np.shape: (100, 16)\n",
      "type(background_cal_np): <class 'numpy.ndarray'>\n",
      "background_cal_np.shape: (100, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Explainer (shapiq + shap) erfolgreich initialisiert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n"
     ]
    }
   ],
   "source": [
    "# Hintergrunddaten (Background samples for explainers)\n",
    "sample_size = 100\n",
    "\n",
    "# Sample and reset index on original processed DataFrames\n",
    "background_bike_df = X_bike_proc_sampled.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "background_cal_df = X_cal_proc_sampled.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Convert sampled backgrounds to NumPy arrays for shapiq TabularExplainer compatibility\n",
    "background_bike_np = background_bike_df.to_numpy()\n",
    "background_cal_np = background_cal_df.to_numpy()\n",
    "\n",
    "# --- Sanity check: Background shape vs. feature names ---\n",
    "print(\"Bike background shape:\", background_bike_np.shape)\n",
    "print(\"Bike feature names len:\", len(feature_names_bike))\n",
    "assert background_bike_np.shape[1] == len(feature_names_bike), \"Mismatch in bike background features!\"\n",
    "\n",
    "print(\"Cal background shape:\", background_cal_np.shape)\n",
    "print(\"Cal feature names len:\", len(feature_names_cal))\n",
    "assert background_cal_np.shape[1] == len(feature_names_cal), \"Mismatch in cal background features!\"\n",
    "\n",
    "# Wrapped predict functions for each model & feature set\n",
    "wrapped_predict_bike_rf = model_predict_wrapper(model_bike_rf, feature_names_bike)\n",
    "wrapped_predict_cal_rf = model_predict_wrapper(model_cal_rf, feature_names_cal)\n",
    "wrapped_predict_bike_lr = model_predict_wrapper(model_bike_lr, feature_names_bike)\n",
    "wrapped_predict_cal_lr = model_predict_wrapper(model_cal_lr, feature_names_cal)\n",
    "\n",
    "# --- shapiq Explainers ---\n",
    "print(f\"type(background_bike_np): {type(background_bike_np)}\")\n",
    "print(f\"background_bike_np.shape: {background_bike_np.shape}\")\n",
    "print(f\"type(background_cal_np): {type(background_cal_np)}\")\n",
    "print(f\"background_cal_np.shape: {background_cal_np.shape}\")\n",
    "\n",
    "# Bike RF shapiq explainers\n",
    "explainer_shapiq_spex_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Cal RF shapiq explainers\n",
    "explainer_shapiq_spex_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Bike LR shapiq explainers\n",
    "explainer_shapiq_spex_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Cal LR shapiq explainers\n",
    "explainer_shapiq_spex_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# --- shap KernelExplainers (reference explainers, expect DataFrames) ---\n",
    "explainer_shap_kernel_bike_rf = shap.KernelExplainer(wrapped_predict_bike_rf, background_bike_df, feature_names=feature_names_bike, max_order=1)\n",
    "explainer_shap_kernel_cal_rf = shap.KernelExplainer(wrapped_predict_cal_rf, background_cal_df, feature_names=feature_names_cal, max_order=1)\n",
    "explainer_shap_kernel_bike_lr = shap.KernelExplainer(wrapped_predict_bike_lr, background_bike_df, feature_names=feature_names_bike, max_order=1)\n",
    "explainer_shap_kernel_cal_lr = shap.KernelExplainer(wrapped_predict_cal_lr, background_cal_df, feature_names=feature_names_cal, max_order=1)\n",
    "\n",
    "print(\"Alle Explainer (shapiq + shap) erfolgreich initialisiert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049dd28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:54.884910Z",
     "start_time": "2025-07-20T20:59:54.876837Z"
    }
   },
   "outputs": [],
   "source": [
    "def l1_error(a, b):\n",
    "    return np.mean(np.abs(a - b))\n",
    "\n",
    "def l2_error(a, b):\n",
    "    return np.mean((a - b) ** 2)\n",
    "\n",
    "def benchmark_shap_explainers(explainers, X, ref_shap_values, budget=1000):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    results = []\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    assert ref_shap_values.shape[0] == n_samples, (\n",
    "        f\"[Fehler] Anzahl Zeilen stimmt nicht √ºberein: X hat {n_samples}, Referenz hat {ref_shap_values.shape[0]}\"\n",
    "    )\n",
    "    assert ref_shap_values.shape[1] == n_features, (\n",
    "        f\"[Fehler] Anzahl Features stimmt nicht √ºberein: X hat {n_features}, Referenz hat {ref_shap_values.shape[1]}\"\n",
    "    )\n",
    "\n",
    "    for name, explainer in explainers.items():\n",
    "        print(f\"‚Üí Benchmarking: {name}\")\n",
    "        try:\n",
    "            start = time.time()\n",
    "            shap_values_list = []\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                # Compute SHAP values\n",
    "                shap_i = explainer.explain(X[i:i+1], budget=budget)\n",
    "                shap_i = np.array(shap_i)\n",
    "\n",
    "                # üîç DEBUG: Print actual shape and type\n",
    "                print(f\"[Debug] Sample {i}, Explainer '{name}':\")\n",
    "                print(f\"         SHAP output shape: {shap_i.shape}\")\n",
    "                print(f\"         Expected shape: ({n_features},)\")\n",
    "                print(f\"         SHAP type: {type(shap_i)}\")\n",
    "\n",
    "                # Check dimensionality\n",
    "                if shap_i.ndim == 1:\n",
    "                    if shap_i.shape[0] == n_features:\n",
    "                        shap_i = shap_i.reshape(1, -1)\n",
    "                    else:\n",
    "                        raise ValueError(f\"[Fehler bei {name}]: SHAP-Array hat falsche L√§nge: {shap_i.shape[0]} statt {n_features}\")\n",
    "                elif shap_i.shape[0] != 1 or shap_i.shape[1] != n_features:\n",
    "                    raise ValueError(f\"[Fehler bei {name}]: Unerwartete SHAP-Form einzelner Instanz: {shap_i.shape}\")\n",
    "\n",
    "                shap_values_list.append(shap_i)\n",
    "\n",
    "            # Stack all SHAP values\n",
    "            shap_values = np.vstack(shap_values_list)\n",
    "            duration = time.time() - start\n",
    "\n",
    "            if shap_values.shape != (n_samples, n_features):\n",
    "                raise ValueError(f\"[Fehler bei {name}]: Finale SHAP-Form ist {shap_values.shape}, erwartet {(n_samples, n_features)}\")\n",
    "\n",
    "            # Compute L2 error\n",
    "            l2_error = np.linalg.norm(shap_values - ref_shap_values)\n",
    "\n",
    "            results.append({\n",
    "                \"method\": name,\n",
    "                \"l2_error\": l2_error,\n",
    "                \"duration_sec\": duration,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Fehler bei {name}]: {e}\")\n",
    "            results.append({\n",
    "                \"method\": name,\n",
    "                \"l2_error\": np.nan,\n",
    "                \"duration_sec\": np.nan\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1272d59",
   "metadata": {},
   "source": [
    "shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ed62ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:01:11.675845Z",
     "start_time": "2025-07-20T20:59:54.924849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechne Referenz-Shapley-Werte (KernelExplainer)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc43b39a37164b678ac5b676b3cd1fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df592fbc61f5445f93924259e5eed1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecb54b8195c45849841f7f20e98bca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7702607dcb242808db23057ee9302ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timeit(func, *args, **kwargs):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    duration = time.time() - start_time\n",
    "    return result, duration\n",
    "\n",
    "ref_sample_size = 50\n",
    "\n",
    "print(\"Berechne Referenz-Shapley-Werte (KernelExplainer)...\")\n",
    "\n",
    "ref_shap_bike_rf, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_bike_rf.shap_values(X_bike_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_cal_rf, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_cal_rf.shap_values(X_cal_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_bike_lr, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_bike_lr.shap_values(X_bike_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_cal_lr, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_cal_lr.shap_values(X_cal_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8d58d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:02:23.470770Z",
     "start_time": "2025-07-20T21:01:11.777685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Validierung...\n",
      "‚Üí ref_shap_bike_rf\n",
      "  OK: shape=(50, 16), dtype=float64\n",
      "‚Üí ref_shap_bike_lr\n",
      "  OK: shape=(50, 16), dtype=float64\n",
      "Starte Validierung...\n",
      "‚Üí ref_shap_cal_rf\n",
      "  OK: shape=(50, 8), dtype=float64\n",
      "‚Üí ref_shap_cal_lr\n",
      "  OK: shape=(50, 8), dtype=float64\n",
      "Benchmark: Bike Sharing - RandomForest\n",
      "‚Üí Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (11,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche L√§nge: 11 statt 16\n",
      "‚Üí Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche L√§nge: 17 statt 16\n",
      "‚Üí Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche L√§nge: 17 statt 16\n",
      "Benchmark: California Housing - RandomForest\n",
      "‚Üí Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "‚Üí Benchmarking: shapiq_svarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\approximator\\montecarlo\\base.py:104: UserWarning: Not all budget is required due to the border-trick.\n",
      "  self._sampler.sample(budget)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "‚Üí Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "Benchmark: Bike Sharing - LinearRegression\n",
      "‚Üí Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 1, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 2, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 3, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 4, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 5, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 6, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 7, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 8, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 9, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 10, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 11, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 12, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 13, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 14, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 15, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 16, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 17, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 18, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 19, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 20, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 21, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 22, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 23, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 24, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 25, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 26, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 27, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 28, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 29, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 30, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 31, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 32, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 33, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 34, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 35, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 36, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 37, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 38, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 39, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 40, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 41, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 42, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 43, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 44, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 45, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 46, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 47, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 48, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 49, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "‚Üí Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche L√§nge: 17 statt 16\n",
      "‚Üí Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche L√§nge: 17 statt 16\n",
      "Benchmark: California Housing - LinearRegression\n",
      "‚Üí Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "‚Üí Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "‚Üí Benchmarking: shapiq_perm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\approximator\\montecarlo\\base.py:104: UserWarning: Not all budget is required due to the border-trick.\n",
      "  self._sampler.sample(budget)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche L√§nge: 9 statt 8\n",
      "Ergebnisse (Beispiel, SVARM):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>l2_error</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shapiq_svarm | Bike-RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   method  l2_error  duration_sec\n",
       "1  shapiq_svarm | Bike-RF       NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "def validate_shapes(ref_dict, n_expected, n_features_expected):\n",
    "    print(\"Starte Validierung...\")\n",
    "\n",
    "    for name, arr in ref_dict.items():\n",
    "        print(f\"‚Üí {name}\")\n",
    "        if arr is None:\n",
    "            print(\"  Fehler: None\")\n",
    "            continue\n",
    "        if isinstance(arr, list):\n",
    "            arr = np.array(arr)\n",
    "        if arr.dtype == \"object\":\n",
    "            print(\"  Fehler: dtype=object\")\n",
    "        if np.isnan(arr).any():\n",
    "            print(\"  Fehler: NaN enthalten\")\n",
    "        if len(arr.shape) != 2:\n",
    "            print(f\"  Fehler: Nicht 2D (shape={arr.shape})\")\n",
    "        elif arr.shape[0] != n_expected:\n",
    "            print(f\"  Warnung: {arr.shape[0]} Zeilen, erwartet: {n_expected}\")\n",
    "        elif arr.shape[1] != n_features_expected:\n",
    "            print(f\"  Warnung: {arr.shape[1]} Features, erwartet: {n_features_expected}\")\n",
    "        else:\n",
    "            print(f\"  OK: shape={arr.shape}, dtype={arr.dtype}\")\n",
    "\n",
    "validate_shapes(\n",
    "    {\n",
    "        \"ref_shap_bike_rf\": ref_shap_bike_rf,\n",
    "        \"ref_shap_bike_lr\": ref_shap_bike_lr,\n",
    "    },\n",
    "    n_expected=ref_sample_size,\n",
    "    n_features_expected=X_bike_proc_sampled.shape[1]\n",
    ")\n",
    "\n",
    "validate_shapes(\n",
    "    {\n",
    "        \"ref_shap_cal_rf\": ref_shap_cal_rf,\n",
    "        \"ref_shap_cal_lr\": ref_shap_cal_lr,\n",
    "    },\n",
    "    n_expected=ref_sample_size,\n",
    "    n_features_expected=X_cal_proc_sampled.shape[1]\n",
    ")\n",
    "\n",
    "# --- Explainer-Dictionaries ---\n",
    "explainers_bike_rf = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_bike_rf,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_bike_rf,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_bike_rf,\n",
    "}\n",
    "\n",
    "explainers_cal_rf = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_cal_rf,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_cal_rf,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_cal_rf,\n",
    "}\n",
    "\n",
    "explainers_bike_lr = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_bike_lr,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_bike_lr,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_bike_lr,\n",
    "}\n",
    "\n",
    "explainers_cal_lr = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_cal_lr,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_cal_lr,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_cal_lr,\n",
    "}\n",
    "\n",
    "# --- Benchmark ---\n",
    "print(\"Benchmark: Bike Sharing - RandomForest\")\n",
    "X_benchmark = X_bike_proc_sampled.iloc[:ref_shap_bike_rf.shape[0]]\n",
    "results_bike_rf = benchmark_shap_explainers(explainers_bike_rf, X_benchmark, ref_shap_bike_rf)\n",
    "\n",
    "print(\"Benchmark: California Housing - RandomForest\")\n",
    "X_benchmark_cal = X_cal_proc_sampled.iloc[:ref_shap_cal_rf.shape[0]]\n",
    "results_cal_rf = benchmark_shap_explainers(explainers_cal_rf, X_benchmark_cal, ref_shap_cal_rf)\n",
    "\n",
    "print(\"Benchmark: Bike Sharing - LinearRegression\")\n",
    "X_benchmark_bike_lr = X_bike_proc_sampled.iloc[:ref_shap_bike_lr.shape[0]]\n",
    "results_bike_lr = benchmark_shap_explainers(explainers_bike_lr, X_benchmark_bike_lr, ref_shap_bike_lr)\n",
    "\n",
    "print(\"Benchmark: California Housing - LinearRegression\")\n",
    "X_benchmark_cal_lr = X_cal_proc_sampled.iloc[:ref_shap_cal_lr.shape[0]]\n",
    "results_cal_lr = benchmark_shap_explainers(explainers_cal_lr, X_benchmark_cal_lr, ref_shap_cal_lr)\n",
    "\n",
    "results_dfs = [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Bike-RF\") for df in [results_bike_rf] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Bike-LR\") for df in [results_bike_lr] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Cal-RF\") for df in [results_cal_rf] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Cal-LR\") for df in [results_cal_lr] if not df.empty\n",
    "]\n",
    "\n",
    "df_results = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "# --- Zusammenf√ºhren ---\n",
    "results_list = []\n",
    "\n",
    "if not results_bike_rf.empty:\n",
    "    results_list.append(results_bike_rf.assign(method=lambda df: df[\"method\"] + \" | Bike-RF\"))\n",
    "if not results_bike_lr.empty:\n",
    "    results_list.append(results_bike_lr.assign(method=lambda df: df[\"method\"] + \" | Bike-LR\"))\n",
    "if not results_cal_rf.empty:\n",
    "    results_list.append(results_cal_rf.assign(method=lambda df: df[\"method\"] + \" | Cal-RF\"))\n",
    "if not results_cal_lr.empty:\n",
    "    results_list.append(results_cal_lr.assign(method=lambda df: df[\"method\"] + \" | Cal-LR\"))\n",
    "\n",
    "df_results = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "print(\"Ergebnisse (Beispiel, SVARM):\")\n",
    "display(df_results[df_results[\"method\"].str.contains(\"svarm\")].head(1))\n",
    "\n",
    "print(\"Benchmark abgeschlossen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f083dad",
   "metadata": {},
   "source": [
    "Ergebnisse in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9df5f7",
   "metadata": {},
   "source": [
    "Visualisierung (Plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c361d9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:02:24.286277Z",
     "start_time": "2025-07-20T21:02:23.567653Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `runtime` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmethod\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mruntime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plt.xticks(rotation=\u001b[32m45\u001b[39m, ha=\u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mDurchschnittliche Laufzeit je Methode und Datensatz\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:2341\u001b[39m, in \u001b[36mbarplot\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[39m\n\u001b[32m   2338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[32m   2339\u001b[39m     estimator = \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m p = \u001b[43m_CategoricalAggPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2351\u001b[39m     ax = plt.gca()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:67\u001b[39m, in \u001b[36m_CategoricalPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     legend=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_format == \u001b[33m\"\u001b[39m\u001b[33mwide\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m         err += \u001b[33m\"\u001b[39m\u001b[33mAn entry with this name does not appear in `data`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m \n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret value `runtime` for `y`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(data=df_results, x=\"method\", y=\"runtime\", errorbar='sd')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Durchschnittliche Laufzeit je Methode und Datensatz\")\n",
    "plt.ylabel(\"Laufzeit (Sekunden)\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(data=df_results, x=\"method\", y=\"quality\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Qualit√§tsfehler (L2-Abweichung) je Methode und Datensatz\")\n",
    "plt.ylabel(\"L2-Abweichung zum Referenz\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.violinplot(data=df_results, x=\"method\", y=\"runtime\", inner=\"quartile\", color=\"skyblue\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Verteilung der Laufzeiten je Methode und Datensatz\")\n",
    "plt.ylabel(\"Laufzeit (Sekunden)\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.violinplot(data=df_results, x=\"method\", y=\"quality\", inner=\"quartile\", color=\"lightcoral\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Verteilung der Qualit√§tsfehler (L2) je Methode und Datensatz\")\n",
    "plt.ylabel(\"L2-Abweichung zum Referenz\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b6e4ddc85b7a0",
   "metadata": {},
   "source": [
    "### Fazit\n",
    "\n",
    "Bei der Ausf√ºhrung der SHAP-Benchmarks sind unerwartet lange Laufzeiten aufgetreten, insbesondere beim Einsatz des KernelExplainer. Dies k√∂nnte auf die hohe Rechenintensit√§t dieses Explainers zur√ºckzuf√ºhren sein, der f√ºr gr√∂√üere Datens√§tze oder komplexe Modelle unverh√§ltnism√§√üig viel Zeit in Anspruch genommen hat.\n",
    "\n",
    "Es wurde festgestellt, dass TreeExplainer und LinearExplainer wesentlich schneller laufen, was diese Methoden f√ºr gr√∂√üere Datens√§tze oder Echtzeitanwendungen besser geeignet macht. Der KernelExplainer hingegen sollte nur mit kleineren Datens√§tzen genutzt werden.\n",
    "\n",
    "F√ºr zuk√ºnftige Tests k√∂nnte es sinnvoll sein, kleinere Teildatens√§tze zu verwenden oder die Hardwareanforderungen zu √ºberpr√ºfen, um die Laufzeit zu verk√ºrzen. Eine zus√§tzliche Optimierung des Codes muss ebenfalls notwendig sein, um die richtige Berechnung ausf√ºhren zu k√∂nnen.\n",
    "\n",
    "Zusammenfassend l√§sst sich sagen, dass trotz implementierter Funktionen und Methoden zur Analyse eine signifikante Laufzeitproblematik besteht, was allerdings nur eine Vermutung ist, da ein korrekter Vergleich aus verschieden Gr√ºnden nicht m√∂glich war."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapiq-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
