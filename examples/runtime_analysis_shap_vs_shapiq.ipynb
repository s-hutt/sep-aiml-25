{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1eee98",
   "metadata": {},
   "source": [
    "# Laufzeitanalyse: SHAP vs SHAPIQ\n",
    "\n",
    "Dieses Notebook vergleicht verschiedene Approximationsverfahren zur Berechnung von Shapley-Werten.\n",
    "\n",
    "### Ziel\n",
    "Analyse von:\n",
    "- Laufzeit (x-Achse)\n",
    "- Approximationsgenauigkeit (L1 & L2 Fehler) gegenüber Referenzwerten\n",
    "\n",
    "##### Verglichene Methoden\n",
    "| Bibliothek | Methode                  |\n",
    "|------------|--------------------------|\n",
    "| `shapiq`   | KernelSHAP, SVARM, PermutationSamplingSV |\n",
    "| `shap`     | KernelExplainer, PermutationExplainer    |\n",
    "\n",
    "##### Datensätze\n",
    "- Bike Sharing\n",
    "- California Housing\n",
    "\n",
    "##### Modelle\n",
    "- Lineare Regression\n",
    "- Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f93473",
   "metadata": {},
   "source": [
    "Imports & Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1152e847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:43.453842Z",
     "start_time": "2025-07-20T20:59:42.282747Z"
    }
   },
   "outputs": [],
   "source": [
    "import shapiq\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import shap\n",
    "from shapiq import TabularExplainer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033f3f8",
   "metadata": {},
   "source": [
    "Daten vorbereiten & subsample Background (für schnellere Laufzeiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7188ab98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:43.525014Z",
     "start_time": "2025-07-20T20:59:43.456837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike Sharing - X shape: (17379, 12) y shape: (17379,)\n",
      "California Housing - X shape: (20640, 8) y shape: (20640,)\n",
      "Sampled preprocessed Bike Sharing shape: (1738, 16)\n",
      "Sampled preprocessed California Housing shape: (2064, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- Daten laden und vorverarbeiten ---\n",
    "\n",
    "X_bike, y_bike = shapiq.datasets.load_bike_sharing()\n",
    "X_cal, y_cal = shapiq.datasets.load_california_housing()\n",
    "\n",
    "print(\"Bike Sharing - X shape:\", X_bike.shape, \"y shape:\", y_bike.shape)\n",
    "print(\"California Housing - X shape:\", X_cal.shape, \"y shape:\", y_cal.shape)\n",
    "\n",
    "def preprocess_data(X, y, categorical_cols=None, sample_size=None):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        if categorical_cols is not None:\n",
    "            X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "        else:\n",
    "            cat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "            X_processed = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    else:\n",
    "        X_processed = pd.DataFrame(X)\n",
    "    \n",
    "    y_processed = pd.Series(y) if not isinstance(y, pd.Series) else y\n",
    "    \n",
    "    if sample_size is not None and len(X_processed) > sample_size:\n",
    "        sampled_indices = X_processed.sample(n=sample_size, random_state=42).index\n",
    "        X_processed = X_processed.loc[sampled_indices].reset_index(drop=True)\n",
    "        y_processed = y_processed.loc[sampled_indices].reset_index(drop=True)\n",
    "    else:\n",
    "        X_processed = X_processed.reset_index(drop=True)\n",
    "        y_processed = y_processed.reset_index(drop=True)\n",
    "    \n",
    "    return X_processed, y_processed\n",
    "\n",
    "bike_categorical_cols = ['season', 'weather']\n",
    "\n",
    "X_bike_proc, y_bike_proc = preprocess_data(X_bike, y_bike, categorical_cols=bike_categorical_cols)\n",
    "X_cal_proc, y_cal_proc = preprocess_data(X_cal, y_cal)\n",
    "\n",
    "sample_fraction = 0.1\n",
    "\n",
    "X_bike_proc_sampled = X_bike_proc.sample(frac=sample_fraction, random_state=42)\n",
    "y_bike_proc_sampled = y_bike_proc.loc[X_bike_proc_sampled.index]\n",
    "\n",
    "X_cal_proc_sampled = X_cal_proc.sample(frac=sample_fraction, random_state=42)\n",
    "y_cal_proc_sampled = y_cal_proc.loc[X_cal_proc_sampled.index]\n",
    "\n",
    "print(\"Sampled preprocessed Bike Sharing shape:\", X_bike_proc_sampled.shape)\n",
    "print(\"Sampled preprocessed California Housing shape:\", X_cal_proc_sampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df289d",
   "metadata": {},
   "source": [
    "Modelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42226904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.144514Z",
     "start_time": "2025-07-20T20:59:43.673427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike Sharing RandomForestRegressor trainiert.\n",
      "California Housing RandomForestRegressor trainiert.\n",
      "Bike Sharing LinearRegression trainiert.\n",
      "California Housing LinearRegression trainiert.\n",
      "Number of features in bike dataset: 16\n",
      "Number of features in cal dataset: 8\n"
     ]
    }
   ],
   "source": [
    "# --- Train-Test Split ---\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
    "    X_bike_proc_sampled, y_bike_proc_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_cal_proc_sampled, y_cal_proc_sampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Modelle trainieren ---\n",
    "\n",
    "model_bike_rf = RandomForestRegressor(random_state=42)\n",
    "model_bike_rf.fit(Xb_train, yb_train)\n",
    "print(\"Bike Sharing RandomForestRegressor trainiert.\")\n",
    "\n",
    "model_cal_rf = RandomForestRegressor(random_state=42)\n",
    "model_cal_rf.fit(Xc_train, yc_train)\n",
    "print(\"California Housing RandomForestRegressor trainiert.\")\n",
    "\n",
    "model_bike_lr = LinearRegression()\n",
    "model_bike_lr.fit(Xb_train, yb_train)\n",
    "print(\"Bike Sharing LinearRegression trainiert.\")\n",
    "\n",
    "model_cal_lr = LinearRegression()\n",
    "model_cal_lr.fit(Xc_train, yc_train)\n",
    "print(\"California Housing LinearRegression trainiert.\")\n",
    "\n",
    "# --- Wrapper Funktion für sauberes predict mit Feature-Namen ---\n",
    "\n",
    "def model_predict_wrapper(model, feature_names):\n",
    "    def predict(X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X, columns=feature_names)\n",
    "        elif isinstance(X, pd.Series):\n",
    "            # convert Series to DataFrame with one row\n",
    "            X = pd.DataFrame([X.values], columns=feature_names)\n",
    "        elif not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be DataFrame, Series, or 2D NumPy array.\")\n",
    "        return model.predict(X)\n",
    "    return predict\n",
    "\n",
    "\n",
    "# Feature-Namen\n",
    "feature_names_bike = X_bike_proc_sampled.columns.tolist()\n",
    "feature_names_cal = X_cal_proc_sampled.columns.tolist()\n",
    "\n",
    "n_features_bike = X_bike_proc_sampled.shape[1]\n",
    "n_features_cal = X_cal_proc_sampled.shape[1]\n",
    "\n",
    "print(f\"Number of features in bike dataset: {n_features_bike}\")\n",
    "print(f\"Number of features in cal dataset: {n_features_cal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10743980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.174285Z",
     "start_time": "2025-07-20T20:59:45.171113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgnosticExplainer', 'Explainer', 'TabPFNExplainer', 'TabularExplainer', 'TreeExplainer', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'agnostic', 'base', 'configuration', 'custom_types', 'tabpfn', 'tabular', 'tree', 'utils', 'validation']\n"
     ]
    }
   ],
   "source": [
    "import shapiq.explainer\n",
    "\n",
    "print(dir(shapiq.explainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382a3a60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.227326Z",
     "start_time": "2025-07-20T20:59:45.224154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'Explainer', 'ExplainerIndices', 'InteractionValues', 'Literal', 'TYPE_CHECKING', 'TabularExplainer', 'TabularExplainerApproximators', 'TabularExplainerImputers', 'TabularExplainerIndices', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'annotations', 'finalize_computed_interactions', 'overrides', 'setup_approximator', 'warn']\n"
     ]
    }
   ],
   "source": [
    "import shapiq.explainer.tabular\n",
    "\n",
    "print(dir(shapiq.explainer.tabular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d3bda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:45.235485Z",
     "start_time": "2025-07-20T20:59:45.232425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typing.Literal['spex', 'montecarlo', 'svarm', 'permutation', 'regression']\n"
     ]
    }
   ],
   "source": [
    "from shapiq.explainer.tabular import TabularExplainerApproximators\n",
    "\n",
    "print(TabularExplainerApproximators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c90bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:54.846953Z",
     "start_time": "2025-07-20T20:59:45.259274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike background shape: (100, 16)\n",
      "Bike feature names len: 16\n",
      "Cal background shape: (100, 8)\n",
      "Cal feature names len: 8\n",
      "type(background_bike_np): <class 'numpy.ndarray'>\n",
      "background_bike_np.shape: (100, 16)\n",
      "type(background_cal_np): <class 'numpy.ndarray'>\n",
      "background_cal_np.shape: (100, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Explainer (shapiq + shap) erfolgreich initialisiert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n",
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\explainer\\validation.py:88: UserWarning: Mismatch between max_order=1 and index=k-SII. k-SII generalizes 'SV'. Setting index to 'SV'.\n",
      "  validated_index = validate_index(index, max_order)\n"
     ]
    }
   ],
   "source": [
    "# Hintergrunddaten (Background samples for explainers)\n",
    "sample_size = 100\n",
    "\n",
    "# Sample and reset index on original processed DataFrames\n",
    "background_bike_df = X_bike_proc_sampled.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "background_cal_df = X_cal_proc_sampled.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Convert sampled backgrounds to NumPy arrays for shapiq TabularExplainer compatibility\n",
    "background_bike_np = background_bike_df.to_numpy()\n",
    "background_cal_np = background_cal_df.to_numpy()\n",
    "\n",
    "# --- Sanity check: Background shape vs. feature names ---\n",
    "print(\"Bike background shape:\", background_bike_np.shape)\n",
    "print(\"Bike feature names len:\", len(feature_names_bike))\n",
    "assert background_bike_np.shape[1] == len(feature_names_bike), \"Mismatch in bike background features!\"\n",
    "\n",
    "print(\"Cal background shape:\", background_cal_np.shape)\n",
    "print(\"Cal feature names len:\", len(feature_names_cal))\n",
    "assert background_cal_np.shape[1] == len(feature_names_cal), \"Mismatch in cal background features!\"\n",
    "\n",
    "# Wrapped predict functions for each model & feature set\n",
    "wrapped_predict_bike_rf = model_predict_wrapper(model_bike_rf, feature_names_bike)\n",
    "wrapped_predict_cal_rf = model_predict_wrapper(model_cal_rf, feature_names_cal)\n",
    "wrapped_predict_bike_lr = model_predict_wrapper(model_bike_lr, feature_names_bike)\n",
    "wrapped_predict_cal_lr = model_predict_wrapper(model_cal_lr, feature_names_cal)\n",
    "\n",
    "# --- shapiq Explainers ---\n",
    "print(f\"type(background_bike_np): {type(background_bike_np)}\")\n",
    "print(f\"background_bike_np.shape: {background_bike_np.shape}\")\n",
    "print(f\"type(background_cal_np): {type(background_cal_np)}\")\n",
    "print(f\"background_cal_np.shape: {background_cal_np.shape}\")\n",
    "\n",
    "# Bike RF shapiq explainers\n",
    "explainer_shapiq_spex_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_bike_rf = shapiq.TabularExplainer(wrapped_predict_bike_rf, background_bike_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Cal RF shapiq explainers\n",
    "explainer_shapiq_spex_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_cal_rf = shapiq.TabularExplainer(wrapped_predict_cal_rf, background_cal_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Bike LR shapiq explainers\n",
    "explainer_shapiq_spex_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_bike_lr = shapiq.TabularExplainer(wrapped_predict_bike_lr, background_bike_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# Cal LR shapiq explainers\n",
    "explainer_shapiq_spex_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"spex\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_svarm_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"svarm\", sample_size=sample_size, max_order=1)\n",
    "explainer_shapiq_perm_cal_lr = shapiq.TabularExplainer(wrapped_predict_cal_lr, background_cal_np, approximator=\"permutation\", sample_size=sample_size, max_order=1)\n",
    "\n",
    "# --- shap KernelExplainers (reference explainers, expect DataFrames) ---\n",
    "explainer_shap_kernel_bike_rf = shap.KernelExplainer(wrapped_predict_bike_rf, background_bike_df, feature_names=feature_names_bike, max_order=1)\n",
    "explainer_shap_kernel_cal_rf = shap.KernelExplainer(wrapped_predict_cal_rf, background_cal_df, feature_names=feature_names_cal, max_order=1)\n",
    "explainer_shap_kernel_bike_lr = shap.KernelExplainer(wrapped_predict_bike_lr, background_bike_df, feature_names=feature_names_bike, max_order=1)\n",
    "explainer_shap_kernel_cal_lr = shap.KernelExplainer(wrapped_predict_cal_lr, background_cal_df, feature_names=feature_names_cal, max_order=1)\n",
    "\n",
    "print(\"Alle Explainer (shapiq + shap) erfolgreich initialisiert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049dd28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:59:54.884910Z",
     "start_time": "2025-07-20T20:59:54.876837Z"
    }
   },
   "outputs": [],
   "source": [
    "def l1_error(a, b):\n",
    "    return np.mean(np.abs(a - b))\n",
    "\n",
    "def l2_error(a, b):\n",
    "    return np.mean((a - b) ** 2)\n",
    "\n",
    "def benchmark_shap_explainers(explainers, X, ref_shap_values, budget=1000):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    results = []\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    assert ref_shap_values.shape[0] == n_samples, (\n",
    "        f\"[Fehler] Anzahl Zeilen stimmt nicht überein: X hat {n_samples}, Referenz hat {ref_shap_values.shape[0]}\"\n",
    "    )\n",
    "    assert ref_shap_values.shape[1] == n_features, (\n",
    "        f\"[Fehler] Anzahl Features stimmt nicht überein: X hat {n_features}, Referenz hat {ref_shap_values.shape[1]}\"\n",
    "    )\n",
    "\n",
    "    for name, explainer in explainers.items():\n",
    "        print(f\"→ Benchmarking: {name}\")\n",
    "        try:\n",
    "            start = time.time()\n",
    "            shap_values_list = []\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                # Compute SHAP values\n",
    "                shap_i = explainer.explain(X[i:i+1], budget=budget)\n",
    "                shap_i = np.array(shap_i)\n",
    "\n",
    "                # 🔍 DEBUG: Print actual shape and type\n",
    "                print(f\"[Debug] Sample {i}, Explainer '{name}':\")\n",
    "                print(f\"         SHAP output shape: {shap_i.shape}\")\n",
    "                print(f\"         Expected shape: ({n_features},)\")\n",
    "                print(f\"         SHAP type: {type(shap_i)}\")\n",
    "\n",
    "                # Check dimensionality\n",
    "                if shap_i.ndim == 1:\n",
    "                    if shap_i.shape[0] == n_features:\n",
    "                        shap_i = shap_i.reshape(1, -1)\n",
    "                    else:\n",
    "                        raise ValueError(f\"[Fehler bei {name}]: SHAP-Array hat falsche Länge: {shap_i.shape[0]} statt {n_features}\")\n",
    "                elif shap_i.shape[0] != 1 or shap_i.shape[1] != n_features:\n",
    "                    raise ValueError(f\"[Fehler bei {name}]: Unerwartete SHAP-Form einzelner Instanz: {shap_i.shape}\")\n",
    "\n",
    "                shap_values_list.append(shap_i)\n",
    "\n",
    "            # Stack all SHAP values\n",
    "            shap_values = np.vstack(shap_values_list)\n",
    "            duration = time.time() - start\n",
    "\n",
    "            if shap_values.shape != (n_samples, n_features):\n",
    "                raise ValueError(f\"[Fehler bei {name}]: Finale SHAP-Form ist {shap_values.shape}, erwartet {(n_samples, n_features)}\")\n",
    "\n",
    "            # Compute L2 error\n",
    "            l2_error = np.linalg.norm(shap_values - ref_shap_values)\n",
    "\n",
    "            results.append({\n",
    "                \"method\": name,\n",
    "                \"l2_error\": l2_error,\n",
    "                \"duration_sec\": duration,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Fehler bei {name}]: {e}\")\n",
    "            results.append({\n",
    "                \"method\": name,\n",
    "                \"l2_error\": np.nan,\n",
    "                \"duration_sec\": np.nan\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1272d59",
   "metadata": {},
   "source": [
    "shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ed62ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:01:11.675845Z",
     "start_time": "2025-07-20T20:59:54.924849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechne Referenz-Shapley-Werte (KernelExplainer)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc43b39a37164b678ac5b676b3cd1fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df592fbc61f5445f93924259e5eed1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecb54b8195c45849841f7f20e98bca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7702607dcb242808db23057ee9302ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timeit(func, *args, **kwargs):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    duration = time.time() - start_time\n",
    "    return result, duration\n",
    "\n",
    "ref_sample_size = 50\n",
    "\n",
    "print(\"Berechne Referenz-Shapley-Werte (KernelExplainer)...\")\n",
    "\n",
    "ref_shap_bike_rf, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_bike_rf.shap_values(X_bike_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_cal_rf, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_cal_rf.shap_values(X_cal_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_bike_lr, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_bike_lr.shap_values(X_bike_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n",
    "\n",
    "ref_shap_cal_lr, _ = timeit(\n",
    "    lambda: np.array(explainer_shap_kernel_cal_lr.shap_values(X_cal_proc_sampled.iloc[:ref_sample_size]))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8d58d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:02:23.470770Z",
     "start_time": "2025-07-20T21:01:11.777685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Validierung...\n",
      "→ ref_shap_bike_rf\n",
      "  OK: shape=(50, 16), dtype=float64\n",
      "→ ref_shap_bike_lr\n",
      "  OK: shape=(50, 16), dtype=float64\n",
      "Starte Validierung...\n",
      "→ ref_shap_cal_rf\n",
      "  OK: shape=(50, 8), dtype=float64\n",
      "→ ref_shap_cal_lr\n",
      "  OK: shape=(50, 8), dtype=float64\n",
      "Benchmark: Bike Sharing - RandomForest\n",
      "→ Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (11,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche Länge: 11 statt 16\n",
      "→ Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche Länge: 17 statt 16\n",
      "→ Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche Länge: 17 statt 16\n",
      "Benchmark: California Housing - RandomForest\n",
      "→ Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "→ Benchmarking: shapiq_svarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\approximator\\montecarlo\\base.py:104: UserWarning: Not all budget is required due to the border-trick.\n",
      "  self._sampler.sample(budget)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "→ Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "Benchmark: Bike Sharing - LinearRegression\n",
      "→ Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 1, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 2, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 3, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 4, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 5, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 6, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 7, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 8, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 9, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 10, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 11, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 12, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 13, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 14, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 15, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 16, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 17, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 18, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 19, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 20, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 21, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 22, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 23, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 24, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 25, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 26, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 27, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 28, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 29, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 30, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 31, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 32, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 33, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 34, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 35, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 36, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 37, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 38, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 39, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 40, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 41, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 42, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 43, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 44, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 45, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 46, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 47, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 48, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Debug] Sample 49, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (16,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "→ Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche Länge: 17 statt 16\n",
      "→ Benchmarking: shapiq_perm\n",
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (17,)\n",
      "         Expected shape: (16,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche Länge: 17 statt 16\n",
      "Benchmark: California Housing - LinearRegression\n",
      "→ Benchmarking: shapiq_spex\n",
      "[Debug] Sample 0, Explainer 'shapiq_spex':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_spex]: [Fehler bei shapiq_spex]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "→ Benchmarking: shapiq_svarm\n",
      "[Debug] Sample 0, Explainer 'shapiq_svarm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_svarm]: [Fehler bei shapiq_svarm]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "→ Benchmarking: shapiq_perm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\shapiq\\approximator\\montecarlo\\base.py:104: UserWarning: Not all budget is required due to the border-trick.\n",
      "  self._sampler.sample(budget)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Sample 0, Explainer 'shapiq_perm':\n",
      "         SHAP output shape: (9,)\n",
      "         Expected shape: (8,)\n",
      "         SHAP type: <class 'numpy.ndarray'>\n",
      "[Fehler bei shapiq_perm]: [Fehler bei shapiq_perm]: SHAP-Array hat falsche Länge: 9 statt 8\n",
      "Ergebnisse (Beispiel, SVARM):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>l2_error</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shapiq_svarm | Bike-RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   method  l2_error  duration_sec\n",
       "1  shapiq_svarm | Bike-RF       NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "def validate_shapes(ref_dict, n_expected, n_features_expected):\n",
    "    print(\"Starte Validierung...\")\n",
    "\n",
    "    for name, arr in ref_dict.items():\n",
    "        print(f\"→ {name}\")\n",
    "        if arr is None:\n",
    "            print(\"  Fehler: None\")\n",
    "            continue\n",
    "        if isinstance(arr, list):\n",
    "            arr = np.array(arr)\n",
    "        if arr.dtype == \"object\":\n",
    "            print(\"  Fehler: dtype=object\")\n",
    "        if np.isnan(arr).any():\n",
    "            print(\"  Fehler: NaN enthalten\")\n",
    "        if len(arr.shape) != 2:\n",
    "            print(f\"  Fehler: Nicht 2D (shape={arr.shape})\")\n",
    "        elif arr.shape[0] != n_expected:\n",
    "            print(f\"  Warnung: {arr.shape[0]} Zeilen, erwartet: {n_expected}\")\n",
    "        elif arr.shape[1] != n_features_expected:\n",
    "            print(f\"  Warnung: {arr.shape[1]} Features, erwartet: {n_features_expected}\")\n",
    "        else:\n",
    "            print(f\"  OK: shape={arr.shape}, dtype={arr.dtype}\")\n",
    "\n",
    "validate_shapes(\n",
    "    {\n",
    "        \"ref_shap_bike_rf\": ref_shap_bike_rf,\n",
    "        \"ref_shap_bike_lr\": ref_shap_bike_lr,\n",
    "    },\n",
    "    n_expected=ref_sample_size,\n",
    "    n_features_expected=X_bike_proc_sampled.shape[1]\n",
    ")\n",
    "\n",
    "validate_shapes(\n",
    "    {\n",
    "        \"ref_shap_cal_rf\": ref_shap_cal_rf,\n",
    "        \"ref_shap_cal_lr\": ref_shap_cal_lr,\n",
    "    },\n",
    "    n_expected=ref_sample_size,\n",
    "    n_features_expected=X_cal_proc_sampled.shape[1]\n",
    ")\n",
    "\n",
    "# --- Explainer-Dictionaries ---\n",
    "explainers_bike_rf = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_bike_rf,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_bike_rf,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_bike_rf,\n",
    "}\n",
    "\n",
    "explainers_cal_rf = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_cal_rf,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_cal_rf,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_cal_rf,\n",
    "}\n",
    "\n",
    "explainers_bike_lr = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_bike_lr,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_bike_lr,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_bike_lr,\n",
    "}\n",
    "\n",
    "explainers_cal_lr = {\n",
    "    \"shapiq_spex\": explainer_shapiq_spex_cal_lr,\n",
    "    \"shapiq_svarm\": explainer_shapiq_svarm_cal_lr,\n",
    "    \"shapiq_perm\": explainer_shapiq_perm_cal_lr,\n",
    "}\n",
    "\n",
    "# --- Benchmark ---\n",
    "print(\"Benchmark: Bike Sharing - RandomForest\")\n",
    "X_benchmark = X_bike_proc_sampled.iloc[:ref_shap_bike_rf.shape[0]]\n",
    "results_bike_rf = benchmark_shap_explainers(explainers_bike_rf, X_benchmark, ref_shap_bike_rf)\n",
    "\n",
    "print(\"Benchmark: California Housing - RandomForest\")\n",
    "X_benchmark_cal = X_cal_proc_sampled.iloc[:ref_shap_cal_rf.shape[0]]\n",
    "results_cal_rf = benchmark_shap_explainers(explainers_cal_rf, X_benchmark_cal, ref_shap_cal_rf)\n",
    "\n",
    "print(\"Benchmark: Bike Sharing - LinearRegression\")\n",
    "X_benchmark_bike_lr = X_bike_proc_sampled.iloc[:ref_shap_bike_lr.shape[0]]\n",
    "results_bike_lr = benchmark_shap_explainers(explainers_bike_lr, X_benchmark_bike_lr, ref_shap_bike_lr)\n",
    "\n",
    "print(\"Benchmark: California Housing - LinearRegression\")\n",
    "X_benchmark_cal_lr = X_cal_proc_sampled.iloc[:ref_shap_cal_lr.shape[0]]\n",
    "results_cal_lr = benchmark_shap_explainers(explainers_cal_lr, X_benchmark_cal_lr, ref_shap_cal_lr)\n",
    "\n",
    "results_dfs = [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Bike-RF\") for df in [results_bike_rf] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Bike-LR\") for df in [results_bike_lr] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Cal-RF\") for df in [results_cal_rf] if not df.empty\n",
    "] + [\n",
    "    df.assign(method=lambda d: d[\"method\"] + \" | Cal-LR\") for df in [results_cal_lr] if not df.empty\n",
    "]\n",
    "\n",
    "df_results = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "# --- Zusammenführen ---\n",
    "results_list = []\n",
    "\n",
    "if not results_bike_rf.empty:\n",
    "    results_list.append(results_bike_rf.assign(method=lambda df: df[\"method\"] + \" | Bike-RF\"))\n",
    "if not results_bike_lr.empty:\n",
    "    results_list.append(results_bike_lr.assign(method=lambda df: df[\"method\"] + \" | Bike-LR\"))\n",
    "if not results_cal_rf.empty:\n",
    "    results_list.append(results_cal_rf.assign(method=lambda df: df[\"method\"] + \" | Cal-RF\"))\n",
    "if not results_cal_lr.empty:\n",
    "    results_list.append(results_cal_lr.assign(method=lambda df: df[\"method\"] + \" | Cal-LR\"))\n",
    "\n",
    "df_results = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "print(\"Ergebnisse (Beispiel, SVARM):\")\n",
    "display(df_results[df_results[\"method\"].str.contains(\"svarm\")].head(1))\n",
    "\n",
    "print(\"Benchmark abgeschlossen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f083dad",
   "metadata": {},
   "source": [
    "Ergebnisse in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9df5f7",
   "metadata": {},
   "source": [
    "Visualisierung (Plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c361d9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T21:02:24.286277Z",
     "start_time": "2025-07-20T21:02:23.567653Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `runtime` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmethod\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mruntime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plt.xticks(rotation=\u001b[32m45\u001b[39m, ha=\u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mDurchschnittliche Laufzeit je Methode und Datensatz\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:2341\u001b[39m, in \u001b[36mbarplot\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[39m\n\u001b[32m   2338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[32m   2339\u001b[39m     estimator = \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m p = \u001b[43m_CategoricalAggPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2351\u001b[39m     ax = plt.gca()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:67\u001b[39m, in \u001b[36m_CategoricalPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     legend=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_format == \u001b[33m\"\u001b[39m\u001b[33mwide\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\YanLiu\\coding_projects\\pythonProjs\\sep-aiml-25\\.venv\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m         err += \u001b[33m\"\u001b[39m\u001b[33mAn entry with this name does not appear in `data`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m \n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret value `runtime` for `y`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(data=df_results, x=\"method\", y=\"runtime\", errorbar='sd')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Durchschnittliche Laufzeit je Methode und Datensatz\")\n",
    "plt.ylabel(\"Laufzeit (Sekunden)\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(data=df_results, x=\"method\", y=\"quality\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Qualitätsfehler (L2-Abweichung) je Methode und Datensatz\")\n",
    "plt.ylabel(\"L2-Abweichung zum Referenz\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.violinplot(data=df_results, x=\"method\", y=\"runtime\", inner=\"quartile\", color=\"skyblue\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Verteilung der Laufzeiten je Methode und Datensatz\")\n",
    "plt.ylabel(\"Laufzeit (Sekunden)\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.violinplot(data=df_results, x=\"method\", y=\"quality\", inner=\"quartile\", color=\"lightcoral\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Verteilung der Qualitätsfehler (L2) je Methode und Datensatz\")\n",
    "plt.ylabel(\"L2-Abweichung zum Referenz\")\n",
    "plt.xlabel(\"Methode | Datensatz\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b6e4ddc85b7a0",
   "metadata": {},
   "source": [
    "### Fazit\n",
    "\n",
    "Bei der Ausführung der SHAP-Benchmarks sind unerwartet lange Laufzeiten aufgetreten, insbesondere beim Einsatz des KernelExplainer. Dies könnte auf die hohe Rechenintensität dieses Explainers zurückzuführen sein, der für größere Datensätze oder komplexe Modelle unverhältnismäßig viel Zeit in Anspruch genommen hat.\n",
    "\n",
    "Es wurde festgestellt, dass TreeExplainer und LinearExplainer wesentlich schneller laufen, was diese Methoden für größere Datensätze oder Echtzeitanwendungen besser geeignet macht. Der KernelExplainer hingegen sollte nur mit kleineren Datensätzen genutzt werden.\n",
    "\n",
    "Für zukünftige Tests könnte es sinnvoll sein, kleinere Teildatensätze zu verwenden oder die Hardwareanforderungen zu überprüfen, um die Laufzeit zu verkürzen. Eine zusätzliche Optimierung des Codes muss ebenfalls notwendig sein, um die richtige Berechnung ausführen zu können.\n",
    "\n",
    "Zusammenfassend lässt sich sagen, dass trotz implementierter Funktionen und Methoden zur Analyse eine signifikante Laufzeitproblematik besteht, was allerdings nur eine Vermutung ist, da ein korrekter Vergleich aus verschieden Gründen nicht möglich war."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapiq-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
